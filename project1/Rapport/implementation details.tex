\section{Implementation Details}

\subsection{Binary Heap}

The Binary Heap was implemented as a binary heap based on the description from~\cite{AlgInC}.
Implementing the Binary Heap on top of an array, as opposed to modelling a tree, has several important advantages, and some disadvantages.

Note that finding the children of a node located at any given position of the array can be easily done by multiplying the position by 2 to find the left child, and additionally adding 1 to find the right child. Vice versa to find parent.

\begin{description}

\item[Space per node] Since we do not need to store pointers to children and parent nodes, we can save quite a bit of space in the node structure.

\item[Total Space] Unfortunately, the array backing the heap needs to be big enough to support the entire heap. We ensure this by specifying it in the constructor, and allocating the array during the heap construction. This means that the heap will need to keep a large chunk of memory alive throughout its lifetime. We save some of this memory by storing only an array of pointers, and allocating space on the heap for the actual nodes as we go along.

Note that this problem can be somewhat avoided by growing or shrinking the array as the size changes (or simply use the vector class), but that might change the worst-case running time of the operations.

\item[Finding the next open position] Finding out where to initially place a new node in the heap is easy when using an array, as the index into the array can be easily computed from the size.

\item[Keeping track of nodes] When decreasing a key in an array-backed Binary Heap, we need to find the position of the node in the array. This unfortunately requires us to keep track of the index of a node as an additional field in the node structure.

\end{description}

\subsection{Fibonacci Heap}

The Fibonacci Heap was implemented following the description from \cite{Cormen}. The Fibonacci heap was implemented over several iterations, and some interesting specifics that were left out of the description from Cormen~\cite{Cormen} were changed a lot during the development.

\begin{description}
\item[Children Lists] The choice of data structure for the children of a node were non-specified, and as such, several options were tried. In the end, it was decided that they would use pointers to locate children, parents and siblings.
\item[Roots List] Just as the children lists, the choice of root list structure was left open. Like for the case of the children lists, it was decided to use pointers, and in fact the roots list is represented using the same pointers from the siblings, since roots have no siblings.
\item[Maximum degree of a Node] During the DeleteMin operation, we need to keep track of unique nodes of specific degrees, this could either be done using a map, or a sufficiently large array. In case of the array, we need to estimate what the largest degree possible in the roots list. This is done by the function $(\lceil \log_2 (n) \rceil +1)*2$. This function is chosen carefully in that it will grow faster than that of the Fibonacci numbers, who grow by approximately $log_\phi$, but only slightly so. Note that this function is much faster to compute than true logarithms, and could even be sped up more by using fast msb, or calling the native \verb#msb# instruction on newer architectures.
\end{description}

\subsubsection{Profiling and incremental development}

Profiling of the Fibonacci Heap was done using the Very Sleepy profiler~\cite{sleepy}. This profiling helped us to do the development in an iterative manner.

At first, a functioning Fibonacci Heap was implemented, using the unordered\_set datastructure from the C++11 stdlib to store children and roots and using a large constant as maximum the degree.

Profiling showed that these sets were absurdly slow, especially when iterating and constructing new sets. They were then replaced by C++11 forward\_lists, using an iterator stored at the node for child deletion, and doing a full rebuild of the root list at DeleteMin operations. This proved to be a great speedup, but profiling still showed that the stdlib data structures took up most of the time during tests.

Finally, the stdlib data structures were replaced by pointers, and the heap started showing good performance, with most of the time spent doing work on the the algorithm itself, or in operating system calls.

Along the way, an approximation for maximum degree was introduced, but it did not seem to make a massive difference in performance.

\subsubsection{Future work for the Fibonacci Heap}

If we were to make the Fibonacci Heap a fully functional we would most likely add the following functionality to it

\begin{description}
\item[IncreaseKey] Increasing the key in a Fibonacci Heap can be done much like the DecreaseKey operation.
\item[MergeHeaps] Heap merging is fairly easy for Fibonacci Heaps if their root list are implemented correctly. Adding either a pointer to the last element of the roots list, or linking the first and last element using the sibling pointers would allow $O(1)$ heap merges.
\item[Fast $log_2$] The approximation for the maximum height is done by bit-shifting to find $log_2$.this could most likely be improved greatly by using either the fast msb from the lectures or the built-in msb instruction of modern processors.
\end{description}