\section{Implementation Details}

\subsection{Binary Heap}

The Binary Heap was implemented as a binary heap based on the description from (TODO: Link to binary heap from io-alg beskrivelse).
Implementing the Binary Heap on top of an array, as opposed to modeling a tree, has several important advantages, and some drawbacks.

Note that finding children/parents of a node located at any given position of the array can be easily done by multiplying/dividing the position by 2 (and adding 1 to find the second child).

\begin{description}

\item[Space per node] Since we do not need to store pointers to children and parent nodes, we can save quite a bit of space in the node structure.

\item[Total Space] Unfortunately, the array backing the heap needs to be big enough to support the entire heap. We ensure this by specifying it in the constructor, and allocating the array during the heap construction. This means that the heap will need to keep a large chunk of memory alive throughout its lifetime. We save some of this memory by storing only an array of pointers, and allocating space on the heap for the actual nodes as we go along.

Note that this problem can be somewhat avoided by growing or shrinking the array as the size changes (or simply use the vector class), but that might change the worst-case running time of the operations.

\item[Finding the next open position] Finding out where to initially place a new node in the heap is easy when using an array, as the index into the array can be easily computed from the size.

\item[Keeping track of nodes] When decreasing a key in an array-backed Binary Heap, we need to find the position of the node in the array. This unfortunately requires us to keep track of the index of a node as an additional field in the node structure.

\end{description}

\subsection{Fibonacci Heap}

The Fibonacci Heap was implemented following the description from (TODO Cormen et al. link). The Fibonacci heap was implemented over several iterations, and some interesting specifics that were left out of the description from Cormen (TODO link) were changed a lot during the development.

\begin{description}
\item[Children Lists] The choice of data structure for the children of a node were non-specified, and as such several options were tried (TODO Link to section on profiling). In the end, it was decided that they would use pointers to locate children, parents and siblings.
\item[Roots List] Just a the children lists, the choice of root list was left open. Like the children lists, it was decided to use pointers, and in fact the roots list is represented using the same pointers from the siblings, since roots have no siblings.
\item[Maximum degree of a Node] During the DeleteMin operation, we need to keep track of unique nodes of specific degrees, this could either be done using a map, or a sufficiently large array. In case of the array, we need to estimate what the largest degree possible in the roots list. This is done by the function $(\lceil \log_2 (n) \rceil +1)*2$. This function is chosen carefully in that it will grow faster than that of the Fibonacci numbers, who grow by approximately $log_\phi$, but only slightly so. Note that this function is much faster to compute that true logarithms, and could even be sped up even more by using fast msb, or calling the native msb instruction on newer architectures.
\end{description}

\subsubsection{Profiling and incremental development}

Profiling of the Fibonacci Heap was done using the Very Sleepy profiler (TODO link to very sleepy). This profiling helped develop the in an iterative manner.

At first, a functioning Fibonacci Heap was implemented using the unordered\_set datastructure to store children and roots, and approximating the maximum degree to a large constant.

Profiling showed, that these set were absurdly slow, especially when iterating and constructing new sets. They were then replaced by forward\_list, using an iterator stored at the node for child deletion, and a full rebuild of the root list at DeleteMin operations. This proved to be a great speedup, but profiling still showed the data structures taking up most of the time during tests.

Finally the data structures were replaced by pointers, and the structure started showing good performance, with most of the time spent doing work on the the algorithm itself, or in operating system calls.

Along the way, the approximation for maximum degree was introduced, but it did not seem to make a massive difference in performance.

\subsubsection{Future work for the Fibonacci Heap}

If we were to make the Fibonacci Heap a fully functional we would most likely add the following functionality to it

\begin{description}
\item[IncreaseKey] Increasing the key in a Fibonacci Heap can be done much like the DecreaseKey operation.
\item[MergeHeaps] Heap merging is fairly easy fo Fibonacci Heaps, if their root list are implemented correctly. Adding either a pointer to the last element of the roots list, or linking the first and last element using the sibling pointers would allow $O(1)$ heap merges.
\item[Fast $log_2$] The approximation for the maximum height is done by bitshifting to find $log_2$.this could most likely be improved greatly by using either the fast msb from the lectures or the built-in msb instruction of modern processors.
\end{description}